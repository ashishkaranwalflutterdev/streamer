<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Listen to Audio</title>
  <style>
    body {
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      height: 100vh;
      background-color: #000;
      font-family: Arial, sans-serif;
      margin: 0;
    }

    h1 {
      margin-bottom: 20px;
      color: #fff;
    }

    #visualization {
      width: 100%;
      height: 150px;
      background-color: #000;
    }
  </style>
</head>
<body>
  <h1>Listening to Audio</h1>
  <audio style="display: none!important;" id="audio" controls autoplay></audio>
  <canvas id="visualization"></canvas>

  <script src="/socket.io/socket.io.js"></script>
  <script>
    const socket = io();
    const audio = document.getElementById('audio');
    const canvas = document.getElementById('visualization');
    const canvasCtx = canvas.getContext('2d');

    // Set up audio context for visualization
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 256; // FFT size for frequency analysis
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    // Connect the audio element to the analyser
    const source = audioContext.createMediaElementSource(audio);
    source.connect(analyser);
    analyser.connect(audioContext.destination);

    // MediaSource for streaming
    const mediaSource = new MediaSource();
    audio.src = URL.createObjectURL(mediaSource);

    let sourceBuffer;

    mediaSource.addEventListener('sourceopen', () => {
      console.log('MediaSource opened');
      sourceBuffer = mediaSource.addSourceBuffer('audio/webm; codecs=opus');
      console.log('SourceBuffer created');
    });

    socket.on('connect', () => {
      console.log('Connected to the server');
    });

    socket.on('audio-stream', (data) => {
      console.log('Audio stream received', data);
      if (data instanceof ArrayBuffer) {
        if (sourceBuffer && !sourceBuffer.updating && mediaSource.readyState === 'open') {
          sourceBuffer.appendBuffer(new Uint8Array(data));
          console.log('Audio data appended to SourceBuffer');
        } else {
          console.log('SourceBuffer not ready for appending');
        }
      } else {
        console.error('Received data is not an ArrayBuffer:', data);
      }
    });

    socket.on('disconnect', () => {
      console.log('Disconnected from the server');
    });

    function draw() {
      requestAnimationFrame(draw);

      analyser.getByteFrequencyData(dataArray);

      canvasCtx.fillStyle = 'rgb(0, 0, 0)';
      canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

      const barCount = 10;
      const barWidth = (canvas.width / (barCount * 2)) - 2; // Width of each bar
      let barHeight;
      const centerX = canvas.width / 2;

      for (let i = 0; i < barCount; i++) {
        // Use the average of some frequency data for each bar
        const barDataIndex = Math.floor((i / barCount) * bufferLength);
        barHeight = dataArray[barDataIndex] / 2;

        // Left side bar
        canvasCtx.fillStyle = 'rgb(0, 255, 128)';
        canvasCtx.fillRect(centerX - (i + 1) * (barWidth + 2), (canvas.height - barHeight) / 2, barWidth, barHeight);

        // Right side bar
        canvasCtx.fillStyle = 'rgb(0, 255, 128)';
        canvasCtx.fillRect(centerX + i * (barWidth + 2), (canvas.height - barHeight) / 2, barWidth, barHeight);
      }
    }

    draw();

    // Resize canvas when the window size changes
    window.addEventListener('resize', () => {
      canvas.width = window.innerWidth * 0.8;  // Adjust the width based on the window size
      canvas.height = 150;
    });

    // Set initial canvas size
    canvas.width = window.innerWidth * 0.8;
    canvas.height = 150;

  </script>
</body>
</html>
